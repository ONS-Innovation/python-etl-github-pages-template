# ${{ values.repository_name }}

[![Build Status](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/ci.yml/badge.svg)](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/ci.yml)
[![Build Status](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/security-scan.yml/badge.svg)](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/security-scan.yml)
{%- if values.is_public_repo %}
[![Build Status](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/codeql.yml/badge.svg)](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions/workflows/codeql.yml)
{%- endif %}
[![Linting: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![${{ values.package_manager }}-managed](https://img.shields.io/badge/${{ values.package_manager }}-managed-blue)](${{ values.package_manager_url }})
[![License - MIT](https://img.shields.io/badge/licence%20-MIT-1ac403.svg)](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/blob/main/LICENSE)

${{ values.repository_description }}

**IMPORTANT**: This README was generated from a template.
Please update it with specific information about your project, including:

> - Detailed project description and purpose
> - Specific installation requirements
> - Usage examples and API documentation
> - Contributing guidelines specific to your project
> - Any project-specific compliance requirements

---

## Table of Contents

[//]: # (:TODO: Enable link checking once https://github.com/tcort/markdown-link-check/issues/250 is resolved.)
<!-- markdown-link-check-disable -->
- [Getting Started](#getting-started)
    - [Pre-requisites](#pre-requisites)
    - [Installation](#installation)
- [Development](#development)
    - [Run Tests with Coverage](#run-tests-with-coverage)
    - [Linting and Formatting](#linting-and-formatting)
    - [Security Scanning](#security-scanning)
- [Contributing](#contributing)
- [License](#license)
<!-- markdown-link-check-enable -->

## Getting Started

To get a local copy up and running, follow these simple steps.

### Pre-requisites

Ensure you have the following installed:

1. **Python**: Version specified in `.python-version`.
2. **[${{ values.package_manager | title }}](${{ values.package_manager_url }})**: This is used to manage package dependencies and virtual
   environments.
3. **Operation System**: MacOS

### Installation

1. Clone the repository and install the required dependencies.

```bash
git clone https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}.git
```

2. Install dependencies

[${{ values.package_manager | title }}](${{ values.package_manager_url }}) is used to manage dependencies in this project. For more information, read
the [${{ values.package_manager | title }} documentation](${{ values.package_manager_url }}).

To install all dependencies, including development dependencies, run:

```bash
make install-dev
```

To install only production dependencies, run:

```bash
make install
   ```

3. Run the application

```bash
make run
```

## ETL Pipeline Usage

This project includes a complete ETL (Extract, Transform, Load) pipeline for processing data{% if values.enable_s3_deployment %} with optional deployment to S3 as a static website{% endif %}.

### Basic Usage

Run the ETL pipeline with the provided example data:

```bash
{% if values.package_manager == 'poetry' %}
poetry run python run_etl.py --source example_data.csv --output results/processed_data.csv
{% else %}
pipenv run python run_etl.py --source example_data.csv --output results/processed_data.csv
{% endif %}
```

### Command Line Options

```bash
# Basic usage
python run_etl.py --source data.csv --output results/processed.csv

# Skip data transformations
python run_etl.py --source data.csv --output results/raw.csv --no-transforms

# Different output formats
python run_etl.py --source data.csv --output results/data.parquet --format parquet
python run_etl.py --source data.csv --output results/data.json --format json

# Verbose logging
python run_etl.py --source data.csv --output results/data.csv --verbose
```

{% if values.enable_s3_deployment %}
### S3 Deployment

Deploy your processed data as a beautiful, interactive web report:

```bash
# Deploy to S3 (uses template configuration)
{% if values.package_manager == 'poetry' %}
poetry run python run_etl.py --source example_data.csv --output results/processed_data.csv --deploy
{% else %}
pipenv run python run_etl.py --source example_data.csv --output results/processed_data.csv --deploy
{% endif %}

# Deploy with custom S3 bucket and project name
python run_etl.py --source data.csv --output results/data.csv --deploy \
  --s3-bucket my-custom-bucket --project-name "My Analytics Dashboard"
```

#### Setup AWS Credentials

Before deploying to S3, ensure your AWS credentials are configured:

**Option 1: GitHub Secrets (Recommended for CI/CD)**
Add the following secrets to your GitHub repository:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

**Option 2: Environment Variables**
```bash
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key
export S3_BUCKET_NAME=${{ values.s3_bucket_name }}
export AWS_REGION=${{ values.aws_region }}
```

#### Automated Deployment

The repository includes a GitHub Actions workflow that automatically:
1. Runs the ETL pipeline on push to main branch
2. Deploys results to S3 as a static website
3. Provides the website URL in workflow output

Access the workflow at: `.github/workflows/etl-deploy.yml`
{% endif %}

### ETL Pipeline Components

The pipeline consists of four main components:

1. **Extract** (`${{ values.module_name }}/extract.py`): Load data from various sources (CSV, Excel, JSON)
2. **Transform** (`${{ values.module_name }}/transform.py`): Clean, validate, and enhance data
3. **Load** (`${{ values.module_name }}/load.py`): Save processed data in multiple formats
{% if values.enable_s3_deployment %}4. **Deploy** (`${{ values.module_name }}/deploy.py`): Generate HTML reports and deploy to S3{% endif %}

### Programmatic Usage

```python
from ${{ values.module_name }} import ETLPipeline

# Initialize pipeline
pipeline = ETLPipeline()

# Run with basic options
success = pipeline.run_pipeline(
    source_path="data.csv",
    output_path="results/processed.csv",
    apply_transforms=True
)

{% if values.enable_s3_deployment %}
# Run with S3 deployment
success = pipeline.run_pipeline(
    source_path="data.csv",
    output_path="results/processed.csv",
    enable_deployment=True,
    s3_bucket_name="my-bucket",
    project_name="My Project"
)

# Get website URL from pipeline summary
if success:
    summary = pipeline.get_pipeline_summary()
    if 'deploy' in summary:
        print(f"Website URL: {summary['deploy']['website_url']}")
{% endif %}
```

## Development

Get started with development by running the following commands.
Before proceeding, make sure you have the development dependencies installed using the `make install-dev` command.

A Makefile is provided to simplify common development tasks. To view all available commands, run:

```bash
make
```

### Run Tests with Coverage

The unit tests are written using the [pytest](https://docs.pytest.org/en/stable/) framework. To run the tests and check
coverage, run:

```bash
make test
```

### Linting and Formatting

[Ruff](https://github.com/astral-sh/ruff) is used for both linting and formatting of the Python code in this project.
Ruff is a fast Python linter and formatter that replaces multiple tools with a single, efficient solution.

The tool is configured using the `pyproject.toml` file.

To lint the Python code, run:

```bash
make lint
```

To auto-format the Python code and correct fixable linting issues, run:

```bash
make format
```

### Security Scanning

[Bandit](https://bandit.readthedocs.io/en/latest/) is used for security scanning of the Python code.
It helps identify common security issues in Python applications.

To run the security scan, run:

```bash
make security-scan
```

### GitHub actions

Linting/formatting and Security Scanning GitHub actions are enabled by default on template repositories. If you go to the `Actions` tab on your [repository](https://github.com/${{ values.repository_owner }}/${{ values.repository_name }}/actions), you can view all the workflows for the repository. If an action has failed, it will show a red circle with a cross in it.

To find out more details about why it failed:

1. Click on the name of the action
2. Click the job in the Jobs section in the left sidebar
3. Find the dropdown with the red circle with a cross in it to view more information about the failed action

Please note that the GitHub actions will not automatically fix the errors, you must resolve them locally.

#### Pre-commit Hooks

The project includes pre-commit hooks to automatically run linting, formatting, and security checks before each commit.

1. Install **pre-commit** using your selected package manager:

{% if values.package_manager == 'poetry' %}
```bash
poetry add --group dev pre-commit
```
{% elif values.package_manager == 'pipenv' %}
```bash
pipenv install --dev pre-commit
```
{% else %}
```bash
pip install pre-commit
```
{% endif %}

2. Activate the git hooks:

```bash
pre-commit install
```

From now on Ruff and Bandit will run automatically on the files you stage before every commit.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## License

See [LICENSE](LICENSE) for details.
